from wordfreq_builder.config import CONFIG, data_filename
import sys

HEADER = """# This file is automatically generated. Do not edit it.
# You can regenerate it using the 'wordfreq-build-deps' command.
"""


def make_ninja_deps(rules_filename, out=sys.stdout):
    """
    Output a complete Ninja file describing how to build the wordfreq data.
    """
    print(HEADER, file=out)
    # Copy in the rules section
    with open(rules_filename, encoding='utf-8') as rulesfile:
        print(rulesfile.read(), file=out)

    language_detect_and_tokenize_deps(
        data_filename('raw-input/twitter/all-2014.txt'),
        slice_prefix=data_filename('slices/twitter/tweets-2014'),
        combined_prefix=data_filename('generated/twitter/tweets-2014'),
        out=out, slices=40
    )


def language_detect_and_tokenize_deps(input_filename, slice_prefix,
                                      combined_prefix, out, slices):
    lines = []
    # split the input into slices
    slice_files = ['{prefix}.part{num:0>2d}'.format(prefix=slice_prefix, num=num)
                   for num in range(slices)]
    build_rule = "build {outs}: split {ins}".format(
        outs=' '.join(slice_files), ins=input_filename
    )
    lines.append(build_rule)
    lines.append("  prefix = {}.part".format(slice_prefix))
    lines.append("  slices = {}".format(slices))
    lines.append("")

    for slicenum in range(slices):
        slice_file = slice_files[slicenum]
        language_outputs = [
            '{prefix}.{lang}.txt'.format(prefix=slice_file, lang=language)
            for language in CONFIG['languages']
        ]
        build_rule = "build {outs}: tokenize_twitter {ins} | wordfreq_builder/tokenizers.py".format(
            outs=' '.join(language_outputs), ins=slice_file
        )
        lines.append(build_rule)
        lines.append("  prefix = {}".format(slice_file))
        lines.append("")

    for language in CONFIG['languages']:
        combined_output = '{prefix}.{lang}.txt'.format(prefix=combined_prefix, lang=language)
        language_inputs = [
            '{prefix}.{lang}.txt'.format(prefix=slice_files[slicenum], lang=language)
            for slicenum in range(slices)
        ]
        build_rule = "build {outs}: cat {ins}".format(
            outs=combined_output,
            ins=' '.join(language_inputs)
        )
        lines.append(build_rule)

    print('\n'.join(lines), file=out)


def main():
    make_ninja_deps('rules.ninja')


if __name__ == '__main__':
    main()
